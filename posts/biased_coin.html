<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sam Roughley</title>
    <link rel="stylesheet" href="../assets/style.css">
    <link rel="icon" type="image/png" sizes="180x180" href="../assets/images/favicon-180.png">
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>

<nav class="navbar">
    <div class="navbar-content">
        <div class="nav-left">
        <a href="../index.html">
            <img src="../assets/images/favicon-180.png" sizes="180x180" alt="Home" class="favicon">
        </a>
        </div>

        <!-- Hamburger icon for mobile -->
        <button class="nav-toggle" aria-label="Toggle navigation">
          ☰
        </button>

        <nav class="nav-right">
        <a href="../index.html">Home</a>   
        <a href="../projects.html">Projects</a>
        <a href="../posts.html">Posts</a>
        <!-- <a href="../photos.html">Photos</a> -->
        </nav>
    </div>
</nav>



<body>

    <main>
        <div class="main-content">

            <a class="go-back" href="../posts.html">&#8592 Go back</a>

          <article class="post">
            <h1 class="post-title-main-page">When can you determine a coin is biased?</h1>
            <p class="post-meta">November 2025 · 5 min read</p>
    
            <p>
              Recently, I've been brushing up on probabilistic reasoning, and so wanted to explore
              some examples of using probability theory to determine something physical. After all,
              there is a large amount of probability theory that can be explored, however theory is 
              only as useful as its applications. Therefore, I wanted to begin with a very simple
              example using one of the standard pieces of equipment in probability problems: a coin.
            </p>
    
            <p>
              Specifically, I wanted to explore the question: <em>If I flip a coin many times, how 
              quickly can I tell whether it's biased?</em> As with all probability questions, such 
              problems can be explored to endless depth. Therefore, as a first exploration, I am taking
              the simplest example. Say we have two coins, one fair and one biased, and we pick a coin
              at random and start flipping, how does our ability to determine whether the coin is biased
              grow?
            </p>

            <p>
              The probability for the number of heads seen (\(n\)) out of \(N\) total flips follows a binomial
              distribution:

              $$ P(n, N) = \binom{N}n p^n (1-p)^{N-n} $$

              where \(p\) is the probability of flipping heads on a single flip. For my example, I take
              \(p=0.6\) for the biased coin, a moderate bias. The resulting distributions for both the fair
              and biased coins are visualised below for growing \(N\).
            </p>
    
            <figure>
              <img src="../assets/posts_photos/biased_coin/distributions.gif" alt="Example image">
              <figcaption>The binomial distributions for the fair and biased coin, with probability p=0.6 of heads with the biased coin</figcaption>
            </figure>

            <p>
              As is clear from the animation, for small \(N\) it is difficult to distinguish the two distriibutions.
              As more flips are introduce (more data obtained), the distributions separate. This is a simple example
              of the power that increasing datset site <em>can</em> have, since with a moderate bias the
              corresponding signal has insufficient time to manifest itself with smaller sample sizes.
            </p>

            <p>
              Going back to the original question, I want to look at our ability to determine whether, after selecting
              a random coin and flipping \(N\) times, we selected the biased coin to flip. This can be done using Bayes'
              theory. Denote \(H_{1}\) as the event we selected the biased coin, we wish to calculate \(P(H_{1} \mid n, N)\),
              the conditional (posterior) probability that we selected the biased coin given we observed \(n\) heads out of 
              \(N\) flips. Using Bayes' theory, this is equal to:

              $$ P(H_{1} \mid n, N) = \frac{P()}{2}$$

              where \(H_{0}\) is the event we picked the fair coin. The second equality comes from ... (all events). Using
              the above equation, we can visualise how the posterior distribution changes with \(n\) and \(N\) as shown below,
              again taking \(p=0.6\) for the biased coin and assuming \(P(H_{0}) = P(H_{1}) = 0.5\).
            </p>

            <figure>
                <img src="../assets/posts_photos/biased_coin/posterior_distribution.gif" alt="Example image">
                <figcaption>Posterior distribution that we selected the biased coin with p=0.6. <strong>Want to fix y-axis</strong></figcaption>
            </figure>

            <p>
              It is clear how, as the number of flips increases, the posterior probability becomes much more decisive. Each time
              we flip the coin, we gain a bit more information that can be used to determine if we have selected the biased
              coin. However, it is important to remember what the above distribution is describing, since the extremes of the 
              distribution can overstate our ability to determine if the coin is biased.
            </p>

            <p>
              The poster distribution \(P(H_{1} \mid n, N)\) quantifies the probability that we selected the biased
              coin <strong>if</strong> we saw \(n\) heads out of \(N\) flips. It does not give any information
              on the probability of having seen those \(n\) heads. Therefore, whilst at the extremes of the distribution
              we have values approaching \(0\) and \(1\), it remains highly unlikely that we observe such an outcome.
              Instead, we are much more likely to observe an outcome near the centre of the distribution, where the 
              probability remains closer to \(50\%\). As a result, the posterior probability alone does not fully
              describe the power of our experiment to determine whether a coin is biased. However, it does provide
              a good example of the use of Bayesian inference.
            </p>

            <!-- <p>
              Can then discuss the use of Bayesian inference to determine the probability we picked the biased coin given
              what we observe, as a clear example of being able to use statistics for a real-world application. Show the equation
              (i.e. Bayes' theory). Maybe also comment on how this is not the probability that we see these outcomes given a biased
              coin, but rather the probability of the coin being the biased coin given our observations (pretty obvious but still
              an important point)
            </p> -->

            <p>
              Whilst the above ideas are very simple, they are the foundations of incredibly important probabilistic
              and statistical concepts, such as hypothesis testing (the above is essentially just a very simple hypothesis
              test), likelihood ratios, and Bayesian model comparison.
            </p>
            <!-- <p>
                Round up the post, discussing how not a huge amount of data is needed when trying to detect a relatively big bias.
                Can comment on how this relates to hypothesis testing (this is essentially just a very simple hypothesis test),
                likelihood ratios, and Bayesian model comparison (maybe link to ML)
            </p> -->

          </article>
        </div>
    </main>

    <!-- Add the footer -->
    <footer class="full-width-footer">
      <div class="footer-content">
        <p>&#169; 2025 Sam Roughley</p>
        <nav>
          <a href="../index.html">Home</a> · 
          <a href="../projects.html">Projects</a> ·
          <a href="../posts.html">Posts</a> 
          <!-- <a href="../photos.html">Photos</a> -->
        </nav>
        <div style="height: 10px;"></div> <!-- blank space -->
        <div class="socials">
          <a href="https://www.linkedin.com/in/samroughley/" target="_blank">
            <img src="../assets/images/linkedin-app-white-icon.webp" alt="LinkedIn" class="social-icon">
          </a>
          <a href="https://github.com/samroughley" target="_blank">
            <img src="../assets/images/github_white_logo.png" alt="GitHub" class="social-icon">
          </a>
        </div>
      </div>
    </footer>

<script src="../assets/script.js"></script>
</body>